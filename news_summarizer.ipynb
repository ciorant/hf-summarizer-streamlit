{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fa4350e4e1a43098f257963e9e877ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_414318f83cca481e95287de4c0f564c5",
              "IPY_MODEL_384b3c9133e445e3a87a9aeba5d284ba",
              "IPY_MODEL_c3b29dfa98ab42bba0b1f356fb169f61"
            ],
            "layout": "IPY_MODEL_abed6d33634b4ebc994bb1643d7e5a7e"
          }
        },
        "414318f83cca481e95287de4c0f564c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_023d0fbeb2534a29b80f119f99884732",
            "placeholder": "​",
            "style": "IPY_MODEL_d4f4302b702e44228dbf81b8fb56f7ac",
            "value": "Map: 100%"
          }
        },
        "384b3c9133e445e3a87a9aeba5d284ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8d4d934575d4ca69e2263f3c4ea2b58",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b538ef184fc4dfbb0c8cbbed89b0a25",
            "value": 100
          }
        },
        "c3b29dfa98ab42bba0b1f356fb169f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1fa835527654d8f9da51132434fbfe9",
            "placeholder": "​",
            "style": "IPY_MODEL_546b990814cb45989e50ee7aef5412c8",
            "value": " 100/100 [00:02&lt;00:00, 40.41 examples/s]"
          }
        },
        "abed6d33634b4ebc994bb1643d7e5a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "023d0fbeb2534a29b80f119f99884732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4f4302b702e44228dbf81b8fb56f7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8d4d934575d4ca69e2263f3c4ea2b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b538ef184fc4dfbb0c8cbbed89b0a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1fa835527654d8f9da51132434fbfe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546b990814cb45989e50ee7aef5412c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install gdown if needed\n",
        "# !pip install gdown\n",
        "\n",
        "# import gdown\n",
        "# gdown.download_folder('your_folder_name')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEiLFgRaNKUc",
        "outputId": "9c1b9883-3bb9-4d7d-db24-ff12be7577b8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1G4UfMB1ecY-OqVcHMfUMAih1B_ZFAf4x config.json\n",
            "Processing file 1OeMWsh5cmQNdFVQU0oZL-Bu3BxXILPdn generation_config.json\n",
            "Processing file 1A52l4M0oI2DOuLkArVPFy56YalQZbWnx merges.txt\n",
            "Processing file 1w8HWz08pf7ImIWTpfCndh23xz1t8ZkzL model.safetensors\n",
            "Processing file 1uOL3kUNc_MbFPWdomNK4p9mkUlNagwwR rng_state.pth\n",
            "Processing file 1qMICI-uzpYoiy2G29feXgTs7U0o6H_Pe scaler.pt\n",
            "Processing file 1tZ62BGy4ze2kEDrG7qfN30r89Op550a3 scheduler.pt\n",
            "Processing file 1l0PXvn7WI0YMRjB4Wmh7NMDJ1DdT5vMH special_tokens_map.json\n",
            "Processing file 1cZ9w8CNKeHDh1IvGN4OmaDDn28JXE2_f tokenizer_config.json\n",
            "Processing file 1sskh5Ae6ZIKGJIMLhTAMiMRlTZpa32jy tokenizer.json\n",
            "Processing file 1cANOyGF2cEyBu1-8OFTp8Dr_GBBV9wWZ trainer_state.json\n",
            "Processing file 1iZ6emNFgnnGJzX_lLUKLqDZLhMwLbUIw training_args.bin\n",
            "Processing file 1DzLvo0rIu_zomtcev6sfXSq0dC8FitsX vocab.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1G4UfMB1ecY-OqVcHMfUMAih1B_ZFAf4x\n",
            "To: /content/checkpoint-3600/config.json\n",
            "100%|██████████| 1.59k/1.59k [00:00<00:00, 7.28MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OeMWsh5cmQNdFVQU0oZL-Bu3BxXILPdn\n",
            "To: /content/checkpoint-3600/generation_config.json\n",
            "100%|██████████| 328/328 [00:00<00:00, 1.19MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A52l4M0oI2DOuLkArVPFy56YalQZbWnx\n",
            "To: /content/checkpoint-3600/merges.txt\n",
            "100%|██████████| 456k/456k [00:00<00:00, 6.03MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1w8HWz08pf7ImIWTpfCndh23xz1t8ZkzL\n",
            "From (redirected): https://drive.google.com/uc?id=1w8HWz08pf7ImIWTpfCndh23xz1t8ZkzL&confirm=t&uuid=65196c25-4817-42b3-8157-2e7f3dfdbf4c\n",
            "To: /content/checkpoint-3600/model.safetensors\n",
            "100%|██████████| 1.63G/1.63G [00:24<00:00, 65.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uOL3kUNc_MbFPWdomNK4p9mkUlNagwwR\n",
            "To: /content/checkpoint-3600/rng_state.pth\n",
            "100%|██████████| 14.6k/14.6k [00:00<00:00, 27.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qMICI-uzpYoiy2G29feXgTs7U0o6H_Pe\n",
            "To: /content/checkpoint-3600/scaler.pt\n",
            "100%|██████████| 1.38k/1.38k [00:00<00:00, 6.01MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tZ62BGy4ze2kEDrG7qfN30r89Op550a3\n",
            "To: /content/checkpoint-3600/scheduler.pt\n",
            "100%|██████████| 1.47k/1.47k [00:00<00:00, 4.15MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1l0PXvn7WI0YMRjB4Wmh7NMDJ1DdT5vMH\n",
            "To: /content/checkpoint-3600/special_tokens_map.json\n",
            "100%|██████████| 279/279 [00:00<00:00, 818kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cZ9w8CNKeHDh1IvGN4OmaDDn28JXE2_f\n",
            "To: /content/checkpoint-3600/tokenizer_config.json\n",
            "100%|██████████| 1.27k/1.27k [00:00<00:00, 4.51MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sskh5Ae6ZIKGJIMLhTAMiMRlTZpa32jy\n",
            "To: /content/checkpoint-3600/tokenizer.json\n",
            "100%|██████████| 3.56M/3.56M [00:00<00:00, 26.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cANOyGF2cEyBu1-8OFTp8Dr_GBBV9wWZ\n",
            "To: /content/checkpoint-3600/trainer_state.json\n",
            "100%|██████████| 12.5k/12.5k [00:00<00:00, 23.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iZ6emNFgnnGJzX_lLUKLqDZLhMwLbUIw\n",
            "To: /content/checkpoint-3600/training_args.bin\n",
            "100%|██████████| 5.91k/5.91k [00:00<00:00, 2.05MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DzLvo0rIu_zomtcev6sfXSq0dC8FitsX\n",
            "To: /content/checkpoint-3600/vocab.json\n",
            "100%|██████████| 798k/798k [00:00<00:00, 8.39MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/checkpoint-3600/config.json',\n",
              " '/content/checkpoint-3600/generation_config.json',\n",
              " '/content/checkpoint-3600/merges.txt',\n",
              " '/content/checkpoint-3600/model.safetensors',\n",
              " '/content/checkpoint-3600/rng_state.pth',\n",
              " '/content/checkpoint-3600/scaler.pt',\n",
              " '/content/checkpoint-3600/scheduler.pt',\n",
              " '/content/checkpoint-3600/special_tokens_map.json',\n",
              " '/content/checkpoint-3600/tokenizer_config.json',\n",
              " '/content/checkpoint-3600/tokenizer.json',\n",
              " '/content/checkpoint-3600/trainer_state.json',\n",
              " '/content/checkpoint-3600/training_args.bin',\n",
              " '/content/checkpoint-3600/vocab.json']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gFox_bRD6F0z"
      },
      "outputs": [],
      "source": [
        "# Install dependencies if needed\n",
        "# !pip install transformers datasets evaluate rouge-score\n",
        "# !pip install sumy\n",
        "# !pip install streamlit gradio\n",
        "# !pip install nltk\n",
        "# !pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", name=\"3.0.0\")\n",
        "print(dataset)\n",
        "print(dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLvC7vCC6Of0",
        "outputId": "f35ea1e9-c3a3-4ccd-e7fe-b52808e1f8b9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['article', 'highlights', 'id'],\n",
            "        num_rows: 287113\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['article', 'highlights', 'id'],\n",
            "        num_rows: 13368\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['article', 'highlights', 'id'],\n",
            "        num_rows: 11490\n",
            "    })\n",
            "})\n",
            "{'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.', 'highlights': \"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .\", 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED=63\n",
        "# Select smaller sets so training is achievable\n",
        "small_train = dataset[\"train\"].shuffle(seed=RANDOM_SEED).select(range(25000))\n",
        "small_val = dataset[\"validation\"].shuffle(seed=RANDOM_SEED).select(range(2000))"
      ],
      "metadata": {
        "id": "qmNhdPZz6pzf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\",model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "text=dataset[\"test\"][0][\"article\"]\n",
        "print(\"Original\", text[:500],\"...\")\n",
        "print(\"Reference: \", dataset[\"test\"][0][\"highlights\"])\n",
        "\n",
        "summary = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
        "print(\"Generated:\", summary[0]['summary_text']) #Sanity check\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7pJ2srX7Rgg",
        "outputId": "e5e9d0c0-22bb-4559-a565-19ffe0c244fb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, includin ...\n",
            "Reference:  Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
            "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
            "Generated: The Palestinian Authority becomes the 123rd member of the International Criminal Court. The move gives the court jurisdiction over alleged crimes in Palestinian territories. Israel and the United States opposed the Palestinians' efforts to join the body.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If needed:\n",
        "# !pip install sumy\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "\n",
        "text = dataset[\"test\"][0][\"article\"]\n",
        "\n",
        "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "summarizer = TextRankSummarizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_02wDgeih27",
        "outputId": "7f41fbb2-1c67-456f-d2b9-6a3bfac85831"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sumy in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.12/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from sumy) (2.32.3)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.12/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from sumy) (3.9.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.12/dist-packages (from breadability>=0.1.20->sumy) (5.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.0.2->sumy) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.0.2->sumy) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.0.2->sumy) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.0.2->sumy) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.7.0->sumy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.7.0->sumy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.7.0->sumy) (2025.8.3)\n",
            "Extractive: \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "checkpoint = \"facebook/bart-large-cnn\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "\n",
        "# Tokenization\n",
        "def preprocess(batch):\n",
        "    inputs = tokenizer(batch[\"article\"],\n",
        "                       max_length=512,\n",
        "                       truncation=True,\n",
        "                       padding=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(batch[\"highlights\"],\n",
        "                           max_length=128,\n",
        "                           truncation=True,\n",
        "                           padding=True)\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "# Dataset.map - applying the tokenizer function to each element of the dataset\n",
        "tokenized_train = small_train.map(\n",
        "    preprocess,\n",
        "    batched=True,\n",
        "    remove_columns=[\"article\", \"highlights\", \"id\"]  # Remove original columns\n",
        ")\n",
        "tokenized_val = small_val.map(\n",
        "    preprocess,\n",
        "    batched=True,\n",
        "    remove_columns=[\"article\", \"highlights\", \"id\"]  # Remove original columns\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676,
          "referenced_widgets": [
            "1fa4350e4e1a43098f257963e9e877ff",
            "414318f83cca481e95287de4c0f564c5",
            "384b3c9133e445e3a87a9aeba5d284ba",
            "c3b29dfa98ab42bba0b1f356fb169f61",
            "abed6d33634b4ebc994bb1643d7e5a7e",
            "023d0fbeb2534a29b80f119f99884732",
            "d4f4302b702e44228dbf81b8fb56f7ac",
            "d8d4d934575d4ca69e2263f3c4ea2b58",
            "4b538ef184fc4dfbb0c8cbbed89b0a25",
            "b1fa835527654d8f9da51132434fbfe9",
            "546b990814cb45989e50ee7aef5412c8"
          ]
        },
        "id": "EZ7t8Yf11llJ",
        "outputId": "4ebb0c0c-704b-45b2-e734-1ba78adafff6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fa4350e4e1a43098f257963e9e877ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4006: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install rouge_score\n",
        "#!pip install evaluate\n",
        "import os\n",
        "import gc\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "\n",
        "# Cleaning GPU (working on Colab)\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Might be useful for VRAM management\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Complicated metrics function with exceptions to prevent overflow which happened without them\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    print(f\"Predictions shape: {predictions.shape}\")\n",
        "    print(f\"Predictions dtype: {predictions.dtype}\")\n",
        "    print(f\"Predictions min/max: {predictions.min()}/{predictions.max()}\")\n",
        "\n",
        "    # Handle predictions - they might be logits, so take argmax\n",
        "    if predictions.ndim == 3:  # If predictions are logits (batch_size, seq_len, vocab_size)\n",
        "        print(\"Taking argmax of 3D predictions (logits)\")\n",
        "        predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "    print(f\"After processing - Predictions min/max: {predictions.min()}/{predictions.max()}\")\n",
        "\n",
        "    # Clip predictions to valid token ID range\n",
        "    max_token_id = tokenizer.vocab_size - 1 if hasattr(tokenizer, 'vocab_size') else 50000\n",
        "    print(f\"Tokenizer vocab size: {getattr(tokenizer, 'vocab_size', 'Unknown')}\")\n",
        "    print(f\"Clipping to max_token_id: {max_token_id}\")\n",
        "\n",
        "    predictions = np.clip(predictions, 0, max_token_id)\n",
        "\n",
        "    # Replace -100s in predictions with pad token id\n",
        "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
        "\n",
        "    # Ensure predictions are int32 and within valid range\n",
        "    predictions = predictions.astype(np.int32)\n",
        "\n",
        "    try:\n",
        "        # Decode predictions\n",
        "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "        print(f\"Successfully decoded {len(decoded_preds)} predictions\")\n",
        "    except (OverflowError, ValueError) as e:\n",
        "        print(f\"Error decoding predictions: {e}\")\n",
        "        # Fallback: create empty predictions\n",
        "        decoded_preds = [\"\"] * len(predictions)\n",
        "\n",
        "    # Decode labels (replace -100 with pad token)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    labels = np.clip(labels, 0, max_token_id)  # Clip labels too for safety\n",
        "    labels = labels.astype(np.int32)\n",
        "\n",
        "    try:\n",
        "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "        print(f\"Successfully decoded {len(decoded_labels)} labels\")\n",
        "    except (OverflowError, ValueError) as e:\n",
        "        print(f\"Error decoding labels: {e}\")\n",
        "        # Fallback: create empty labels\n",
        "        decoded_labels = [\"\"] * len(labels)\n",
        "\n",
        "    # Compute ROUGE only if we have valid decoded text\n",
        "    if any(decoded_preds) and any(decoded_labels):\n",
        "        try:\n",
        "            result = rouge.compute(\n",
        "                predictions=decoded_preds,\n",
        "                references=decoded_labels,\n",
        "                use_stemmer=True\n",
        "            )\n",
        "\n",
        "            print(f\"ROUGE scores computed successfully\")\n",
        "            # Return selected ROUGE scores\n",
        "            return {\n",
        "                \"rouge1\": result[\"rouge1\"],\n",
        "                \"rouge2\": result[\"rouge2\"],\n",
        "                \"rougeL\": result[\"rougeL\"],\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error computing ROUGE: {e}\")\n",
        "            return {\n",
        "                \"rouge1\": 0.0,\n",
        "                \"rouge2\": 0.0,\n",
        "                \"rougeL\": 0.0,\n",
        "            }\n",
        "    else:\n",
        "        print(\"No valid decoded text found, returning zero scores\")\n",
        "        # Return zero scores if decoding failed\n",
        "        return {\n",
        "            \"rouge1\": 0.0,\n",
        "            \"rouge2\": 0.0,\n",
        "            \"rougeL\": 0.0,\n",
        "        }\n",
        "\n",
        "\n",
        "# Data collator\n",
        "collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer, model=model, padding=True\n",
        ")\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/model_checkpoints\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    save_total_limit=3,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=1,\n",
        "    eval_accumulation_steps=16,\n",
        "    predict_with_generate=True,\n",
        "    generation_num_beams=2,\n",
        "    generation_max_length=256,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=3e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"rouge1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    logging_dir=\"logs\",\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Resuming from checkpoint (in my case, 3600)\n",
        "resume_from = \"/content/checkpoint-NUMBER\"\n",
        "\n",
        "# Check if it exists\n",
        "if os.path.exists(resume_from):\n",
        "    print(f\"Using checkpoint: {resume_from}\")\n",
        "    trainer.train(resume_from_checkpoint=resume_from)\n",
        "else:\n",
        "    print(\"Checkpoint not found, starting fresh\")\n",
        "    trainer.train()\n",
        "\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"final_model\")\n",
        "tokenizer.save_pretrained(\"final_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LOZ9Qoe9LYII",
        "outputId": "664e356e-6a5e-4104-91af-8becd88298ff"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1G4UfMB1ecY-OqVcHMfUMAih1B_ZFAf4x config.json\n",
            "Processing file 1OeMWsh5cmQNdFVQU0oZL-Bu3BxXILPdn generation_config.json\n",
            "Processing file 1A52l4M0oI2DOuLkArVPFy56YalQZbWnx merges.txt\n",
            "Processing file 1w8HWz08pf7ImIWTpfCndh23xz1t8ZkzL model.safetensors\n",
            "Processing file 1uOL3kUNc_MbFPWdomNK4p9mkUlNagwwR rng_state.pth\n",
            "Processing file 1qMICI-uzpYoiy2G29feXgTs7U0o6H_Pe scaler.pt\n",
            "Processing file 1tZ62BGy4ze2kEDrG7qfN30r89Op550a3 scheduler.pt\n",
            "Processing file 1l0PXvn7WI0YMRjB4Wmh7NMDJ1DdT5vMH special_tokens_map.json\n",
            "Processing file 1cZ9w8CNKeHDh1IvGN4OmaDDn28JXE2_f tokenizer_config.json\n",
            "Processing file 1sskh5Ae6ZIKGJIMLhTAMiMRlTZpa32jy tokenizer.json\n",
            "Processing file 1cANOyGF2cEyBu1-8OFTp8Dr_GBBV9wWZ trainer_state.json\n",
            "Processing file 1iZ6emNFgnnGJzX_lLUKLqDZLhMwLbUIw training_args.bin\n",
            "Processing file 1DzLvo0rIu_zomtcev6sfXSq0dC8FitsX vocab.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1G4UfMB1ecY-OqVcHMfUMAih1B_ZFAf4x\n",
            "To: /content/checkpoint-3600/config.json\n",
            "100%|██████████| 1.59k/1.59k [00:00<00:00, 6.03MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OeMWsh5cmQNdFVQU0oZL-Bu3BxXILPdn\n",
            "To: /content/checkpoint-3600/generation_config.json\n",
            "100%|██████████| 328/328 [00:00<00:00, 1.38MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A52l4M0oI2DOuLkArVPFy56YalQZbWnx\n",
            "To: /content/checkpoint-3600/merges.txt\n",
            "100%|██████████| 456k/456k [00:00<00:00, 6.34MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1w8HWz08pf7ImIWTpfCndh23xz1t8ZkzL\n",
            "From (redirected): https://drive.google.com/uc?id=1w8HWz08pf7ImIWTpfCndh23xz1t8ZkzL&confirm=t&uuid=478ca686-a8e7-47c7-9237-4888cb8565a2\n",
            "To: /content/checkpoint-3600/model.safetensors\n",
            "100%|██████████| 1.63G/1.63G [00:22<00:00, 71.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uOL3kUNc_MbFPWdomNK4p9mkUlNagwwR\n",
            "To: /content/checkpoint-3600/rng_state.pth\n",
            "100%|██████████| 14.6k/14.6k [00:00<00:00, 41.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qMICI-uzpYoiy2G29feXgTs7U0o6H_Pe\n",
            "To: /content/checkpoint-3600/scaler.pt\n",
            "100%|██████████| 1.38k/1.38k [00:00<00:00, 6.58MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tZ62BGy4ze2kEDrG7qfN30r89Op550a3\n",
            "To: /content/checkpoint-3600/scheduler.pt\n",
            "100%|██████████| 1.47k/1.47k [00:00<00:00, 5.69MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1l0PXvn7WI0YMRjB4Wmh7NMDJ1DdT5vMH\n",
            "To: /content/checkpoint-3600/special_tokens_map.json\n",
            "100%|██████████| 279/279 [00:00<00:00, 1.10MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cZ9w8CNKeHDh1IvGN4OmaDDn28JXE2_f\n",
            "To: /content/checkpoint-3600/tokenizer_config.json\n",
            "100%|██████████| 1.27k/1.27k [00:00<00:00, 5.27MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sskh5Ae6ZIKGJIMLhTAMiMRlTZpa32jy\n",
            "To: /content/checkpoint-3600/tokenizer.json\n",
            "100%|██████████| 3.56M/3.56M [00:00<00:00, 27.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cANOyGF2cEyBu1-8OFTp8Dr_GBBV9wWZ\n",
            "To: /content/checkpoint-3600/trainer_state.json\n",
            "100%|██████████| 12.5k/12.5k [00:00<00:00, 35.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iZ6emNFgnnGJzX_lLUKLqDZLhMwLbUIw\n",
            "To: /content/checkpoint-3600/training_args.bin\n",
            "100%|██████████| 5.91k/5.91k [00:00<00:00, 18.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DzLvo0rIu_zomtcev6sfXSq0dC8FitsX\n",
            "To: /content/checkpoint-3600/vocab.json\n",
            "100%|██████████| 798k/798k [00:00<00:00, 7.64MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4252444020.py:148: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using checkpoint: /content/checkpoint-3600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
            "Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
            "\teval_steps: 500 (from args) != 200 (from trainer_state.json)\n",
            "\tsave_steps: 500 (from args) != 200 (from trainer_state.json)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4637' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4637/6250 39:01 < 1:00:49, 0.44 it/s, Epoch 1.48/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.504300</td>\n",
              "      <td>1.063339</td>\n",
              "      <td>0.453779</td>\n",
              "      <td>0.216304</td>\n",
              "      <td>0.302864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.495500</td>\n",
              "      <td>1.089444</td>\n",
              "      <td>0.422003</td>\n",
              "      <td>0.190148</td>\n",
              "      <td>0.273031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.776700</td>\n",
              "      <td>1.019952</td>\n",
              "      <td>0.432371</td>\n",
              "      <td>0.200777</td>\n",
              "      <td>0.278550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.791000</td>\n",
              "      <td>1.005972</td>\n",
              "      <td>0.435188</td>\n",
              "      <td>0.202099</td>\n",
              "      <td>0.292370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.811200</td>\n",
              "      <td>1.013479</td>\n",
              "      <td>0.436497</td>\n",
              "      <td>0.208488</td>\n",
              "      <td>0.284821</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions shape: (100, 176)\n",
            "Predictions dtype: int64\n",
            "Predictions min/max: -100/50141\n",
            "After processing - Predictions min/max: -100/50141\n",
            "Tokenizer vocab size: 50265\n",
            "Clipping to max_token_id: 50264\n",
            "Successfully decoded 100 predictions\n",
            "Successfully decoded 100 labels\n",
            "ROUGE scores computed successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:3917: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions shape: (100, 256)\n",
            "Predictions dtype: int64\n",
            "Predictions min/max: -100/50141\n",
            "After processing - Predictions min/max: -100/50141\n",
            "Tokenizer vocab size: 50265\n",
            "Clipping to max_token_id: 50264\n",
            "Successfully decoded 100 predictions\n",
            "Successfully decoded 100 labels\n",
            "ROUGE scores computed successfully\n",
            "Predictions shape: (100, 176)\n",
            "Predictions dtype: int64\n",
            "Predictions min/max: -100/50141\n",
            "After processing - Predictions min/max: -100/50141\n",
            "Tokenizer vocab size: 50265\n",
            "Clipping to max_token_id: 50264\n",
            "Successfully decoded 100 predictions\n",
            "Successfully decoded 100 labels\n",
            "ROUGE scores computed successfully\n",
            "Predictions shape: (100, 161)\n",
            "Predictions dtype: int64\n",
            "Predictions min/max: -100/50118\n",
            "After processing - Predictions min/max: -100/50118\n",
            "Tokenizer vocab size: 50265\n",
            "Clipping to max_token_id: 50264\n",
            "Successfully decoded 100 predictions\n",
            "Successfully decoded 100 labels\n",
            "ROUGE scores computed successfully\n",
            "Predictions shape: (100, 166)\n",
            "Predictions dtype: int64\n",
            "Predictions min/max: -100/50141\n",
            "After processing - Predictions min/max: -100/50141\n",
            "Tokenizer vocab size: 50265\n",
            "Clipping to max_token_id: 50264\n",
            "Successfully decoded 100 predictions\n",
            "Successfully decoded 100 labels\n",
            "ROUGE scores computed successfully\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4252444020.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Using checkpoint: {resume_from}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"❌ Checkpoint not found, starting fresh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2239\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2585\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m                     ):\n\u001b[1;32m   2589\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Load model and tokenizer from a specific checkpoint\n",
        "checkpoint_path = \"/content/your-checkpoint-path\"\n",
        "\n",
        "print(\"Loading model from checkpoint...\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10fo9rtmfDh_",
        "outputId": "bf4ed036-186e-47be-b328-8ef9da1db2e9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from checkpoint...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/bart/configuration_bart.py:177: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function for news summarization\n",
        "def test_summarization(article_text, max_length=128):\n",
        "    inputs = tokenizer(article_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "            do_sample=False,\n",
        "            length_penalty=1.0\n",
        "        )\n",
        "\n",
        "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Test 1: Technology News\n",
        "test_article_1 = \"\"\"\n",
        "Apple announced today that it will be releasing a major software update for its iPhone lineup next month. The iOS 18.2 update includes several new artificial intelligence features, improved battery management, and enhanced security protocols. The company's CEO stated that this update represents the most significant advancement in iPhone software in the past three years. Early beta testers have reported improvements in app performance and faster charging speeds. The update will be available for iPhone 12 and newer models, with older devices receiving a limited version of the features. Apple's stock price rose 3% following the announcement, as investors showed confidence in the company's continued innovation in the mobile technology sector.\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== TEST 1: Technology News ===\")\n",
        "print(\"Original article length:\", len(test_article_1.split()))\n",
        "print(\"\\nGenerated summary:\")\n",
        "summary_1 = test_summarization(test_article_1)\n",
        "print(summary_1)\n",
        "print(f\"\\nSummary length: {len(summary_1.split())} words\")\n",
        "\n",
        "# Test 2: Politics/Economy News\n",
        "test_article_2 = \"\"\"\n",
        "The Federal Reserve announced a 0.25% interest rate cut yesterday, marking the third reduction this year as officials attempt to stimulate economic growth amid concerns about global trade tensions. Fed Chair Jerome Powell explained that the decision was made to support continued expansion and maintain price stability. Economists had mixed reactions to the announcement, with some arguing that further cuts may be necessary while others warned about potential inflationary pressures. The stock market responded positively, with major indices gaining over 2% in after-hours trading. Small businesses are expected to benefit from lower borrowing costs, while savers may see reduced returns on deposits. The next Federal Open Market Committee meeting is scheduled for December, where additional rate changes will be considered based on economic data and employment figures.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\\n=== TEST 2: Politics/Economy News ===\")\n",
        "print(\"Original article length:\", len(test_article_2.split()))\n",
        "print(\"\\nGenerated summary:\")\n",
        "summary_2 = test_summarization(test_article_2)\n",
        "print(summary_2)\n",
        "print(f\"\\nSummary length: {len(summary_2.split())} words\")\n",
        "\n",
        "def clean_summary(text):\n",
        "    # Remove spaces before punctuation\n",
        "    import re\n",
        "    text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)\n",
        "    # Clean up multiple spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Apply to your summary\n",
        "clean_summary_2 = clean_summary(summary_2)\n",
        "print(\"Cleaned:\", clean_summary_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKvLFtfBfOzk",
        "outputId": "5a75e03d-4ff7-4bc9-a48f-c29987cdf1eb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEST 1: Technology News ===\n",
            "Original article length: 111\n",
            "\n",
            "Generated summary:\n",
            "Apple will release iOS 18.2 next month .\n",
            "The update will be available for iPhone 12 and newer models, with older devices receiving a limited version .\n",
            "Apple's stock price rose 3% following the announcement .\n",
            "Investors showed confidence in the company's continued innovation .\n",
            "\n",
            "Summary length: 45 words\n",
            "\n",
            "\n",
            "=== TEST 2: Politics/Economy News ===\n",
            "Original article length: 127\n",
            "\n",
            "Generated summary:\n",
            "The Federal Reserve announced a 0.25% interest rate cut yesterday .\n",
            "It is the third reduction this year .\n",
            "The move is expected to stimulate economic growth .\n",
            "Analysts had mixed reactions to the announcement .\n",
            "Some argued that further cuts may be necessary while others warned about potential inflationary pressures .\n",
            "\n",
            "Summary length: 52 words\n",
            "Cleaned: The Federal Reserve announced a 0.25% interest rate cut yesterday. It is the third reduction this year. The move is expected to stimulate economic growth. Analysts had mixed reactions to the announcement. Some argued that further cuts may be necessary while others warned about potential inflationary pressures.\n"
          ]
        }
      ]
    }
  ]
}